{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b9c74a",
   "metadata": {},
   "source": [
    "# M2 Data Science - NLP \n",
    "\n",
    "#### Hugo Rialan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d93c8",
   "metadata": {},
   "source": [
    "## Research paper analysis: \n",
    "\n",
    "### <u>A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db91dc",
   "metadata": {},
   "source": [
    "Link of the paper: https://aclanthology.org/2020.acl-main.514/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54df580",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to show that preprocessing tools on text are an important step before using these texts in more complicated AI models. \n",
    "\n",
    "To show this we will build a simple recurrent neural network. We will classify movie reviews from IMDB by good or bad feelings using this network. We will first train the network without preprocessing techniques and then using simple preprocessing techniques like stemming.\n",
    "\n",
    "We will then compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c6378",
   "metadata": {},
   "source": [
    "We will use:\n",
    "- __nltk__ and __keras__ for text preprocessing\n",
    "- __keras__ to build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc709018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388a9c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hugorialan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hugorialan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6bc09",
   "metadata": {},
   "source": [
    "I have defined here some global variables according to the power of my computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff6e8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_review = 15000 # max = 25000\n",
    "max_review_length = 100\n",
    "train_size = int(nb_review * 0.6)\n",
    "\n",
    "vocabulary_size = 5000 \n",
    "embedding_vector_length = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb6ac6",
   "metadata": {},
   "source": [
    "The following function is one of the most important. It will allow the preprocessing of a text. Depending on its arguments, we can add a preprocessing technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24413507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, basic=True, pos=False, removeStopwords=False, stemming=False):\n",
    "    \"\"\"\n",
    "    Preprocess a text in the order given in the article: Basic, Part Of Speech, Stop Words, Stemming.\n",
    "    Not all the preprocessing techniques of the article are implemented.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    good_tags = ['NN', 'VB', 'JJ', 'RB'] # Tags taken from the article, page 5802\n",
    "    \n",
    "    # Basic\n",
    "    if basic:\n",
    "        remove_special_char = re.compile('r[^a-z\\d]', re.IGNORECASE)\n",
    "        replace_numerics = re.compile(r'\\d+', re.IGNORECASE)\n",
    "        text = remove_special_char.sub('', text)\n",
    "        text = replace_numerics.sub('', text)\n",
    "\n",
    "    text = text.lower().split()\n",
    "    processedText = []\n",
    "    \n",
    "    # Part Of Speech\n",
    "    if pos:\n",
    "        pos_tag_text = pos_tag(text)\n",
    "        text = [text[i] for i in range(len(text)) if pos_tag_text[i][1] in good_tags]\n",
    "        \n",
    "    for word in text:\n",
    "         # Stop Words\n",
    "        if removeStopwords:\n",
    "             if word in stop_words:\n",
    "                    continue    #stop the loop  for this word and continue to the following word\n",
    "            \n",
    "        # Stemming\n",
    "        if stemming:\n",
    "            word = stemmer.stem(word)\n",
    "        \n",
    "        processedText.append(word)\n",
    "        \n",
    "    text = ' '.join(processedText)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f22f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('./IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd1517cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59918cf5",
   "metadata": {},
   "source": [
    "Our dataset is quite simple. Reviews are labelled with there sentiment class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904ceeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = imdb[:nb_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1017a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393575d",
   "metadata": {},
   "source": [
    "Then, I created a DataFrame in order to store our results and print them at the end of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "253aad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    " \n",
    "data = {'Processing':[],\n",
    "        \n",
    "        'Accuracy': [],\n",
    "        'F-score':[]\n",
    "       }\n",
    " \n",
    "df_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e1aa4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd3966a",
   "metadata": {},
   "source": [
    "## 1 - Just a Basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc60c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [preprocessing(text,basic=True, pos=False, removeStopwords=False, stemming=False) for text in list(imdb['review'])]\n",
    "y = np.array([1 if sentiment=='positive' else 0 for sentiment in list(imdb['sentiment'])])\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(x)\n",
    "x = pad_sequences(tokenizer.texts_to_sequences(x), maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddeaf59",
   "metadata": {},
   "source": [
    "For all our experiments, we preprocess the data and separate them into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b02ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test = x[:train_size], x[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1568ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f4f1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13a5a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_vector_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fff6767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 242,561\n",
      "Trainable params: 242,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14bdc3",
   "metadata": {},
   "source": [
    "Then, We use a recurrent neural network to solve our classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6161f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "141/141 [==============================] - 15s 98ms/step - loss: 0.5449 - accuracy: 0.7054 - val_loss: 0.4313 - val_accuracy: 0.8090\n",
      "Epoch 2/3\n",
      "141/141 [==============================] - 14s 97ms/step - loss: 0.3210 - accuracy: 0.8693 - val_loss: 0.3650 - val_accuracy: 0.8385\n",
      "Epoch 3/3\n",
      "141/141 [==============================] - 13s 95ms/step - loss: 0.2329 - accuracy: 0.9111 - val_loss: 0.3886 - val_accuracy: 0.8260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1f12c4df0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=3, batch_size=64, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "211c6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.60%\n",
      "F score: 83.10\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = [int(pred >= 0.5) for pred in model.predict(x_test).ravel()]\n",
    "df_results = df_results.append({'Processing' : 'Basic', \n",
    "                \n",
    "                'Accuracy' : (scores[1]*100), \n",
    "                'F-score' : (f1_score(y_test, y_pred)*100)\n",
    "               }, ignore_index=True)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"F score: %.2f\" % (f1_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab5e2e6",
   "metadata": {},
   "source": [
    "I computed the F-score because this is the score that they used in the research paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebce595",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845aabe",
   "metadata": {},
   "source": [
    "## 2 - Basic, POS, remove stopwords, Stemming on train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e3dbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [preprocessing(text, basic=True, pos=True, removeStopwords=True, stemming=True) for text in list(imdb['review'])]\n",
    "y = np.array([1 if sentiment=='positive' else 0 for sentiment in list(imdb['sentiment'])])\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(x)\n",
    "x = pad_sequences(tokenizer.texts_to_sequences(x), maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26349755",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test = x[:train_size], x[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebb6952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf98beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dabe5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_vector_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df2879d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "141/141 [==============================] - 15s 96ms/step - loss: 0.5875 - accuracy: 0.6806 - val_loss: 0.3986 - val_accuracy: 0.8248\n",
      "Epoch 2/3\n",
      "141/141 [==============================] - 13s 95ms/step - loss: 0.3164 - accuracy: 0.8727 - val_loss: 0.3886 - val_accuracy: 0.8277\n",
      "Epoch 3/3\n",
      "141/141 [==============================] - 14s 96ms/step - loss: 0.2347 - accuracy: 0.9147 - val_loss: 0.4014 - val_accuracy: 0.8312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1f12bcc40>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=3, batch_size=64, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3125d789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.12%\n",
      "F score: 81.74\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = [int(pred >= 0.5) for pred in model.predict(x_test).ravel()]\n",
    "df_results = df_results.append({'Processing' : 'All', \n",
    "                \n",
    "                'Accuracy' : (scores[1]*100), \n",
    "                'F-score' : (f1_score(y_test, y_pred)*100)\n",
    "               }, ignore_index=True)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"F score: %.2f\" % (f1_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256607cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b02db8d",
   "metadata": {},
   "source": [
    "## 3 - All - POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a481f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [preprocessing(text, basic=True, pos=False, removeStopwords=True, stemming=True) for text in list(imdb['review'])]\n",
    "y = np.array([1 if sentiment=='positive' else 0 for sentiment in list(imdb['sentiment'])])\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(x)\n",
    "x = pad_sequences(tokenizer.texts_to_sequences(x), maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2520824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test = x[:train_size], x[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b91aa5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68e8a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6095d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_vector_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef61fc64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "141/141 [==============================] - 15s 96ms/step - loss: 0.5249 - accuracy: 0.7284 - val_loss: 0.3655 - val_accuracy: 0.8417\n",
      "Epoch 2/3\n",
      "141/141 [==============================] - 15s 108ms/step - loss: 0.2762 - accuracy: 0.8906 - val_loss: 0.3586 - val_accuracy: 0.8553\n",
      "Epoch 3/3\n",
      "141/141 [==============================] - 14s 96ms/step - loss: 0.2111 - accuracy: 0.9229 - val_loss: 0.4168 - val_accuracy: 0.8412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1f31baaf0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=3, batch_size=64, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ce6dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.12%\n",
      "F score: 84.57\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = [int(pred >= 0.5) for pred in model.predict(x_test).ravel()]\n",
    "df_results = df_results.append({'Processing' : 'All - pos', \n",
    "                \n",
    "                'Accuracy' : (scores[1]*100), \n",
    "                'F-score' : (f1_score(y_test, y_pred)*100)\n",
    "               }, ignore_index=True)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"F score: %.2f\" % (f1_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e4c48b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f50c33",
   "metadata": {},
   "source": [
    "## 4 - All - STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0d69364",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [preprocessing(text, basic=True, pos=True, removeStopwords=False, stemming=True) for text in list(imdb['review'])]\n",
    "y = np.array([1 if sentiment=='positive' else 0 for sentiment in list(imdb['sentiment'])])\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(x)\n",
    "x = pad_sequences(tokenizer.texts_to_sequences(x), maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8e44fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test = x[:train_size], x[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16e69c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f057686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b94b9443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_vector_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "680d0c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "141/141 [==============================] - 15s 96ms/step - loss: 0.5928 - accuracy: 0.6876 - val_loss: 0.4063 - val_accuracy: 0.8215\n",
      "Epoch 2/3\n",
      "141/141 [==============================] - 13s 96ms/step - loss: 0.3163 - accuracy: 0.8717 - val_loss: 0.3730 - val_accuracy: 0.8362\n",
      "Epoch 3/3\n",
      "141/141 [==============================] - 14s 100ms/step - loss: 0.2170 - accuracy: 0.9177 - val_loss: 0.3910 - val_accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1dca56a90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=3, batch_size=64, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "730fbf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.47%\n",
      "F score: 83.54\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = [int(pred >= 0.5) for pred in model.predict(x_test).ravel()]\n",
    "df_results = df_results.append({'Processing' : 'All - stop', \n",
    "                \n",
    "                'Accuracy' : (scores[1]*100), \n",
    "                'F-score' : (f1_score(y_test, y_pred)*100)\n",
    "               }, ignore_index=True)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"F score: %.2f\" % (f1_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f22988",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b28286",
   "metadata": {},
   "source": [
    "## 5 - All - STEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03366cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [preprocessing(text, basic=True, pos=True, removeStopwords=True, stemming=False) for text in list(imdb['review'])]\n",
    "y = np.array([1 if sentiment=='positive' else 0 for sentiment in list(imdb['sentiment'])])\n",
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(x)\n",
    "x = pad_sequences(tokenizer.texts_to_sequences(x), maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7f06876",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test = x[:train_size], x[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91b44d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63f7a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dce95635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_vector_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cfcbe4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "141/141 [==============================] - 15s 96ms/step - loss: 0.5321 - accuracy: 0.7410 - val_loss: 0.3960 - val_accuracy: 0.8222\n",
      "Epoch 2/3\n",
      "141/141 [==============================] - 13s 95ms/step - loss: 0.2851 - accuracy: 0.8833 - val_loss: 0.3628 - val_accuracy: 0.8448\n",
      "Epoch 3/3\n",
      "141/141 [==============================] - 14s 96ms/step - loss: 0.2051 - accuracy: 0.9233 - val_loss: 0.3888 - val_accuracy: 0.8408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1de38c910>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=3, batch_size=64, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3932363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.08%\n",
      "F score: 83.30\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = [int(pred >= 0.5) for pred in model.predict(x_test).ravel()]\n",
    "df_results = df_results.append({'Processing' : 'All - stem', \n",
    "                \n",
    "                'Accuracy' : (scores[1]*100), \n",
    "                'F-score' : (f1_score(y_test, y_pred)*100)\n",
    "               }, ignore_index=True)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"F score: %.2f\" % (f1_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228476e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ac3a1",
   "metadata": {},
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dc99b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------+\n",
      "| Processing | Accuracy | F-score |\n",
      "+------------+----------+---------+\n",
      "|   Basic    |   82.6   |  83.1   |\n",
      "|    All     |  83.12   |  81.74  |\n",
      "| All - pos  |  84.12   |  84.57  |\n",
      "| All - stop |  84.47   |  83.54  |\n",
      "| All - stem |  84.08   |  83.3   |\n",
      "+------------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    " print(tabulate(round(df_results, 2), headers='keys', tablefmt='pretty',showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f7207",
   "metadata": {},
   "source": [
    "Finally, if we look at the accuracy, There is indeed an improvement of the results between Basic and All. The best result for accuracy is All-stop. This is interesting because in the research paper on page 5805, it is specified in the table that their best result for IMDB was also obtained with All-stop. The worst results are with All-stem, which confirms the importance of stemming.\n",
    "\n",
    "If we look at the F-score, the best results are with All-pos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74558d9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f43dbbf",
   "metadata": {},
   "source": [
    "sources:\n",
    "- Natural Language Processing courses from Chloé Clavel and Matthieu Labeau\n",
    "- Deep Learning 1 courses from G. Peeters and A. Newson\n",
    "- https://www.kaggle.com/natlee/sentiment-analysis-of-imdb-50k-with-keras-model/data?select=IMDB+Dataset.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
